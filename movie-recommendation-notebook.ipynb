{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# ğŸ¬ Movie Recommendation System - Data Exploration\n",
    "\n",
    "**Project**: Movie Recommendation Engine  \n",
    "**Author**: Ayush Jaggi  \n",
    "**Date**: September 2024\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Notebook Overview\n",
    "\n",
    "Welcome to the first part of my movie recommendation system! In this notebook, I'll explore the MovieLens dataset to understand:\n",
    "\n",
    "- ğŸ­ **Movie characteristics** - genres, release years, popularity\n",
    "- ğŸ‘¥ **User behavior** - rating patterns, preferences, demographics\n",
    "- â­ **Rating distributions** - how people rate movies\n",
    "- ğŸ“Š **Data quality** - missing values, outliers, data consistency\n",
    "\n",
    "This exploration will guide my recommendation algorithm design and help identify interesting business insights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ¬ Welcome to Movie Recommendation System Analysis!\")\n",
    "print(f\"ğŸ“… Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸš€ Let's explore some movie data!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Loading & Initial Exploration\n",
    "\n",
    "Let me load the MovieLens dataset and get our first look at the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "source": [
    "# Load the datasets\n",
    "print(\"ğŸ“¥ Loading MovieLens dataset...\")\n",
    "\n",
    "# Load movies data\n",
    "movies_df = pd.read_csv('../data/movies.csv')\n",
    "print(f\"ğŸ¬ Movies dataset shape: {movies_df.shape}\")\n",
    "\n",
    "# Load ratings data  \n",
    "ratings_df = pd.read_csv('../data/ratings.csv')\n",
    "print(f\"â­ Ratings dataset shape: {ratings_df.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "print(f\"\\nğŸ“Š Dataset Overview:\")\n",
    "print(f\"   ğŸ­ Total Movies: {len(movies_df):,}\")\n",
    "print(f\"   ğŸ‘¥ Total Users: {ratings_df['userId'].nunique():,}\")\n",
    "print(f\"   â­ Total Ratings: {len(ratings_df):,}\")\n",
    "print(f\"   ğŸ“… Rating Period: {pd.to_datetime(ratings_df['timestamp'], unit='s').dt.year.min()} - {pd.to_datetime(ratings_df['timestamp'], unit='s').dt.year.max()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "source": [
    "# Examine the structure of our datasets\n",
    "print(\"ğŸ” Movies Dataset Structure:\")\n",
    "print(movies_df.head())\n",
    "print(f\"\\nColumns: {list(movies_df.columns)}\")\n",
    "print(f\"Data types:\\n{movies_df.dtypes}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"â­ Ratings Dataset Structure:\")\n",
    "print(ratings_df.head())\n",
    "print(f\"\\nColumns: {list(ratings_df.columns)}\")\n",
    "print(f\"Data types:\\n{ratings_df.dtypes}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## ğŸ­ Movie Analysis\n",
    "\n",
    "Let's dive deep into understanding our movie catalog - what genres are popular, when were movies released, and how are they distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "source": [
    "# Extract release year from movie titles\n",
    "movies_df['year'] = movies_df['title'].str.extract(r'\\((\\d{4})\\)')[0]\n",
    "movies_df['year'] = pd.to_numeric(movies_df['year'], errors='coerce')\n",
    "\n",
    "# Clean movie titles (remove year)\n",
    "movies_df['title_clean'] = movies_df['title'].str.replace(r'\\s*\\(\\d{4}\\)\\s*$', '', regex=True)\n",
    "\n",
    "print(\"ğŸ¬ Movie Release Year Analysis:\")\n",
    "print(f\"   ğŸ“… Earliest movie: {movies_df['year'].min():.0f}\")\n",
    "print(f\"   ğŸ“… Latest movie: {movies_df['year'].max():.0f}\")\n",
    "print(f\"   ğŸ“Š Average release year: {movies_df['year'].mean():.1f}\")\n",
    "print(f\"   â“ Movies with missing year: {movies_df['year'].isna().sum()}\")\n",
    "\n",
    "# Display some examples\n",
    "print(\"\\nğŸ­ Sample movies with extracted years:\")\n",
    "print(movies_df[['title', 'title_clean', 'year', 'genres']].head(10))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "source": [
    "# Analyze movie genres\n",
    "print(\"ğŸ­ Genre Analysis:\")\n",
    "\n",
    "# Split genres and count frequency\n",
    "all_genres = []\n",
    "for genres_str in movies_df['genres'].dropna():\n",
    "    if genres_str != '(no genres listed)':\n",
    "        genres = genres_str.split('|')\n",
    "        all_genres.extend(genres)\n",
    "\n",
    "genre_counts = pd.Series(all_genres).value_counts()\n",
    "\n",
    "print(f\"ğŸ“Š Total unique genres: {len(genre_counts)}\")\n",
    "print(f\"\\nğŸ† Top 10 Most Popular Genres:\")\n",
    "for i, (genre, count) in enumerate(genre_counts.head(10).items(), 1):\n",
    "    percentage = (count / len(movies_df)) * 100\n",
    "    print(f\"   {i:2d}. {genre:15s}: {count:4d} movies ({percentage:5.1f}%)\")\n",
    "\n",
    "# Visualize genre distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_genres = genre_counts.head(15)\n",
    "plt.barh(range(len(top_genres)), top_genres.values, color='skyblue')\n",
    "plt.yticks(range(len(top_genres)), top_genres.index)\n",
    "plt.xlabel('Number of Movies')\n",
    "plt.title('ğŸ“Š Movie Distribution by Genre (Top 15)', fontsize=16, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(top_genres.values):\n",
    "    plt.text(v + 10, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "source": [
    "# Analyze movie release trends over time\n",
    "yearly_movies = movies_df.groupby('year').size().reset_index(name='movie_count')\n",
    "yearly_movies = yearly_movies[yearly_movies['year'].between(1920, 2020)]  # Filter reasonable years\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(yearly_movies['year'], yearly_movies['movie_count'], marker='o', linewidth=2, markersize=4)\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.title('ğŸ“ˆ Movie Production Trends Over Time', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight interesting periods\n",
    "plt.axvspan(1990, 2000, alpha=0.2, color='yellow', label='90s Movie Boom')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print insights\n",
    "peak_year = yearly_movies.loc[yearly_movies['movie_count'].idxmax(), 'year']\n",
    "peak_count = yearly_movies['movie_count'].max()\n",
    "print(f\"ğŸ† Peak movie production year: {peak_year:.0f} with {peak_count} movies\")\n",
    "\n",
    "# Decade analysis\n",
    "movies_df['decade'] = (movies_df['year'] // 10) * 10\n",
    "decade_counts = movies_df.groupby('decade').size().sort_index()\n",
    "\n",
    "print(f\"\\nğŸ“Š Movies by Decade:\")\n",
    "for decade, count in decade_counts.items():\n",
    "    if pd.notna(decade) and decade >= 1920:\n",
    "        print(f\"   {decade:.0f}s: {count:4d} movies\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## â­ Rating Behavior Analysis\n",
    "\n",
    "Now let's understand how users rate movies. This will be crucial for building our recommendation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "source": [
    "# Basic rating statistics\n",
    "print(\"â­ Rating Distribution Analysis:\")\n",
    "print(f\"   ğŸ“Š Total ratings: {len(ratings_df):,}\")\n",
    "print(f\"   ğŸ“Š Rating range: {ratings_df['rating'].min()} - {ratings_df['rating'].max()}\")\n",
    "print(f\"   ğŸ“Š Average rating: {ratings_df['rating'].mean():.2f}\")\n",
    "print(f\"   ğŸ“Š Median rating: {ratings_df['rating'].median():.1f}\")\n",
    "print(f\"   ğŸ“Š Most common rating: {ratings_df['rating'].mode().iloc[0]:.1f}\")\n",
    "\n",
    "# Rating distribution\n",
    "rating_dist = ratings_df['rating'].value_counts().sort_index()\n",
    "print(f\"\\nğŸ¯ Rating Distribution:\")\n",
    "for rating, count in rating_dist.items():\n",
    "    percentage = (count / len(ratings_df)) * 100\n",
    "    print(f\"   {rating}â­: {count:7,} ratings ({percentage:5.1f}%)\")\n",
    "\n",
    "# Visualize rating distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(rating_dist.index, rating_dist.values, color='orange', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Rating')\n",
    "ax1.set_ylabel('Number of Ratings')\n",
    "ax1.set_title('ğŸ“Š Rating Distribution (Count)', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add percentage labels\n",
    "for rating, count in rating_dist.items():\n",
    "    percentage = (count / len(ratings_df)) * 100\n",
    "    ax1.text(rating, count + 1000, f'{percentage:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(rating_dist)))\n",
    "ax2.pie(rating_dist.values, labels=[f'{r}â­' for r in rating_dist.index], \n",
    "        autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title('ğŸ“Š Rating Distribution (Percentage)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "source": [
    "# User behavior analysis\n",
    "user_stats = ratings_df.groupby('userId').agg({\n",
    "    'rating': ['count', 'mean', 'std'],\n",
    "    'movieId': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "user_stats.columns = ['num_ratings', 'avg_rating', 'rating_std', 'unique_movies']\n",
    "user_stats = user_stats.reset_index()\n",
    "\n",
    "print(\"ğŸ‘¥ User Behavior Analysis:\")\n",
    "print(f\"   ğŸ“Š Total users: {len(user_stats):,}\")\n",
    "print(f\"   ğŸ“Š Average ratings per user: {user_stats['num_ratings'].mean():.1f}\")\n",
    "print(f\"   ğŸ“Š Median ratings per user: {user_stats['num_ratings'].median():.0f}\")\n",
    "print(f\"   ğŸ“Š Most active user rated: {user_stats['num_ratings'].max()} movies\")\n",
    "print(f\"   ğŸ“Š Least active user rated: {user_stats['num_ratings'].min()} movies\")\n",
    "\n",
    "# User activity distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Number of ratings per user\n",
    "axes[0,0].hist(user_stats['num_ratings'], bins=50, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_xlabel('Number of Ratings per User')\n",
    "axes[0,0].set_ylabel('Number of Users')\n",
    "axes[0,0].set_title('ğŸ“Š User Activity Distribution', fontweight='bold')\n",
    "axes[0,0].axvline(user_stats['num_ratings'].mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {user_stats[\"num_ratings\"].mean():.1f}')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Average rating per user\n",
    "axes[0,1].hist(user_stats['avg_rating'], bins=30, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "axes[0,1].set_xlabel('Average Rating per User')\n",
    "axes[0,1].set_ylabel('Number of Users')\n",
    "axes[0,1].set_title('ğŸ“Š User Rating Tendency', fontweight='bold')\n",
    "axes[0,1].axvline(user_stats['avg_rating'].mean(), color='red', linestyle='--',\n",
    "                  label=f'Mean: {user_stats[\"avg_rating\"].mean():.2f}')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Rating standard deviation\n",
    "axes[1,0].hist(user_stats['rating_std'].dropna(), bins=30, color='orange', alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_xlabel('Rating Standard Deviation')\n",
    "axes[1,0].set_ylabel('Number of Users')\n",
    "axes[1,0].set_title('ğŸ“Š User Rating Consistency', fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# User categories\n",
    "user_categories = []\n",
    "for _, user in user_stats.iterrows():\n",
    "    if user['num_ratings'] < 20:\n",
    "        category = 'Light User (<20 ratings)'\n",
    "    elif user['num_ratings'] < 50:\n",
    "        category = 'Moderate User (20-50 ratings)'\n",
    "    elif user['num_ratings'] < 100:\n",
    "        category = 'Active User (50-100 ratings)'\n",
    "    else:\n",
    "        category = 'Heavy User (100+ ratings)'\n",
    "    user_categories.append(category)\n",
    "\n",
    "user_category_counts = pd.Series(user_categories).value_counts()\n",
    "\n",
    "axes[1,1].pie(user_category_counts.values, labels=user_category_counts.index, \n",
    "              autopct='%1.1f%%', startangle=90)\n",
    "axes[1,1].set_title('ğŸ‘¥ User Activity Categories', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ‘¥ User Categories:\")\n",
    "for category, count in user_category_counts.items():\n",
    "    percentage = (count / len(user_stats)) * 100\n",
    "    print(f\"   {category}: {count:4d} users ({percentage:5.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## ğŸ¬ Movie Popularity Analysis\n",
    "\n",
    "Let's identify the most popular and highest-rated movies to understand what makes content successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "source": [
    "# Movie popularity analysis\n",
    "movie_stats = ratings_df.groupby('movieId').agg({\n",
    "    'rating': ['count', 'mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "movie_stats.columns = ['num_ratings', 'avg_rating', 'rating_std']\n",
    "movie_stats = movie_stats.reset_index()\n",
    "\n",
    "# Merge with movie information\n",
    "movie_analysis = movie_stats.merge(movies_df[['movieId', 'title', 'genres', 'year']], \n",
    "                                  on='movieId', how='left')\n",
    "\n",
    "print(\"ğŸ¬ Movie Popularity Analysis:\")\n",
    "print(f\"   ğŸ“Š Total movies with ratings: {len(movie_analysis):,}\")\n",
    "print(f\"   ğŸ“Š Average ratings per movie: {movie_analysis['num_ratings'].mean():.1f}\")\n",
    "print(f\"   ğŸ“Š Median ratings per movie: {movie_analysis['num_ratings'].median():.0f}\")\n",
    "print(f\"   ğŸ“Š Most rated movie has: {movie_analysis['num_ratings'].max()} ratings\")\n",
    "\n",
    "# Top rated movies (with minimum 50 ratings)\n",
    "popular_movies = movie_analysis[movie_analysis['num_ratings'] >= 50].copy()\n",
    "popular_movies = popular_movies.sort_values('avg_rating', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ† Top 10 Highest Rated Movies (min 50 ratings):\")\n",
    "for i, (_, movie) in enumerate(popular_movies.head(10).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {movie['title']:35s} | â­{movie['avg_rating']:.2f} | ğŸ‘¥{movie['num_ratings']:3.0f} ratings\")\n",
    "\n",
    "# Most popular movies (by number of ratings)\n",
    "most_rated = movie_analysis.sort_values('num_ratings', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ”¥ Top 10 Most Rated Movies:\")\n",
    "for i, (_, movie) in enumerate(most_rated.head(10).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {movie['title']:35s} | ğŸ‘¥{movie['num_ratings']:4.0f} ratings | â­{movie['avg_rating']:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "source": [
    "# Visualize movie popularity vs rating relationship\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot: Number of ratings vs Average rating\n",
    "axes[0].scatter(movie_analysis['num_ratings'], movie_analysis['avg_rating'], \n",
    "               alpha=0.6, s=30, color='purple')\n",
    "axes[0].set_xlabel('Number of Ratings (Popularity)')\n",
    "axes[0].set_ylabel('Average Rating')\n",
    "axes[0].set_title('ğŸ“Š Movie Popularity vs Quality', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(movie_analysis['num_ratings'], movie_analysis['avg_rating'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0].plot(movie_analysis['num_ratings'], p(movie_analysis['num_ratings']), \n",
    "            \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "# Highlight some famous movies\n",
    "famous_movies = movie_analysis[movie_analysis['num_ratings'] >= 200]\n",
    "axes[0].scatter(famous_movies['num_ratings'], famous_movies['avg_rating'], \n",
    "               s=80, color='red', alpha=0.8, label='Popular Movies (200+ ratings)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Movie rating distribution\n",
    "axes[1].hist(movie_analysis['num_ratings'], bins=50, color='skyblue', \n",
    "            alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Number of Ratings per Movie')\n",
    "axes[1].set_ylabel('Number of Movies')\n",
    "axes[1].set_title('ğŸ“Š Movie Rating Count Distribution', fontweight='bold')\n",
    "axes[1].set_yscale('log')  # Log scale due to long tail\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add vertical lines for quartiles\n",
    "quartiles = movie_analysis['num_ratings'].quantile([0.25, 0.5, 0.75])\n",
    "for q, value in quartiles.items():\n",
    "    axes[1].axvline(value, color='red', linestyle='--', alpha=0.7, \n",
    "                   label=f'Q{int(q*4)}: {value:.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print insights about the long tail\n",
    "print(f\"\\nğŸ“Š Movie Rating Distribution Insights:\")\n",
    "print(f\"   25% of movies have â‰¤ {quartiles[0.25]:.0f} ratings\")\n",
    "print(f\"   50% of movies have â‰¤ {quartiles[0.5]:.0f} ratings\")\n",
    "print(f\"   75% of movies have â‰¤ {quartiles[0.75]:.0f} ratings\")\n",
    "\n",
    "# Cold start problem analysis\n",
    "movies_with_few_ratings = len(movie_analysis[movie_analysis['num_ratings'] < 10])\n",
    "percentage_cold_start = (movies_with_few_ratings / len(movie_analysis)) * 100\n",
    "print(f\"   â„ï¸ Cold start movies (<10 ratings): {movies_with_few_ratings} ({percentage_cold_start:.1f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## ğŸ• Temporal Analysis\n",
    "\n",
    "Let's understand how rating behavior changes over time - are there seasonal patterns or trends we should know about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "source": [
    "# Convert timestamp to datetime\n",
    "ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "ratings_df['date'] = ratings_df['timestamp'].dt.date\n",
    "ratings_df['year'] = ratings_df['timestamp'].dt.year\n",
    "ratings_df['month'] = ratings_df['timestamp'].dt.month\n",
    "ratings_df['weekday'] = ratings_df['timestamp'].dt.dayofweek\n",
    "ratings_df['hour'] = ratings_df['timestamp'].dt.hour\n",
    "\n",
    "print(\"ğŸ• Temporal Rating Patterns:\")\n",
    "print(f\"   ğŸ“… Rating period: {ratings_df['timestamp'].min().strftime('%Y-%m-%d')} to {ratings_df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   ğŸ“Š Total days: {(ratings_df['timestamp'].max() - ratings_df['timestamp'].min()).days} days\")\n",
    "print(f\"   ğŸ“Š Average ratings per day: {len(ratings_df) / (ratings_df['timestamp'].max() - ratings_df['timestamp'].min()).days:.1f}\")\n",
    "\n",
    "# Monthly rating trends\n",
    "monthly_ratings = ratings_df.groupby(['year', 'month']).size().reset_index(name='rating_count')\n",
    "monthly_ratings['date'] = pd.to_datetime(monthly_ratings[['year', 'month']].assign(day=1))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(monthly_ratings['date'], monthly_ratings['rating_count'], \n",
    "         marker='o', linewidth=2, markersize=4, color='navy')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.title('ğŸ“ˆ Rating Activity Over Time', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Highlight peak period\n",
    "peak_month = monthly_ratings.loc[monthly_ratings['rating_count'].idxmax()]\n",
    "plt.annotate(f'Peak: {peak_month[\"rating_count\"]} ratings\\n{peak_month[\"date\"].strftime(\"%B %Y\")}',\n",
    "             xy=(peak_month['date'], peak_month['rating_count']),\n",
    "             xytext=(10, 10), textcoords='offset points',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "source": [
    "# Analyze rating patterns by day of week and hour\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Day of week patterns\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_ratings = ratings_df.groupby('weekday').size()\n",
    "\n",
    "axes[0,0].bar(range(7), weekday_ratings.values, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_xticks(range(7))\n",
    "axes[0,0].set_xticklabels(weekday_names, rotation=45)\n",
    "axes[0,0].set_ylabel('Number of Ratings')\n",
    "axes[0,0].set_title('ğŸ“Š Rating Activity by Day of Week', fontweight='bold')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Hour of day patterns\n",
    "hourly_ratings = ratings_df.groupby('hour').size()\n",
    "\n",
    "axes[0,1].plot(hourly_ratings.index, hourly_ratings.values, marker='o', linewidth=2, color='green')\n",
    "axes[0,1].set_xlabel('Hour of Day')\n",
    "axes[0,1].set_ylabel('Number of Ratings')\n",
    "axes[0,1].set_title('ğŸ“Š Rating Activity by Hour of Day', fontweight='bold')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Monthly patterns (seasonal)\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "monthly_patterns = ratings_df.groupby('month').size()\n",
    "\n",
    "axes[1,0].bar(range(1, 13), monthly_patterns.values, color='orange', alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_xticks(range(1, 13))\n",
    "axes[1,0].set_xticklabels(month_names, rotation=45)\n",
    "axes[1,0].set_ylabel('Number of Ratings')\n",
    "axes[1,0].set_title('ğŸ“Š Rating Activity by Month', fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Average rating by month (quality trends)\n",
    "monthly_avg_rating = ratings_df.groupby('month')['rating'].mean()\n",
    "\n",
    "axes[1,1].plot(range(1, 13), monthly_avg_rating.values, marker='s', \n",
    "               linewidth=2, color='red', markersize=6)\n",
    "axes[1,1].set_xticks(range(1, 13))\n",
    "axes[1,1].set_xticklabels(month_names, rotation=45)\n",
    "axes[1,1].set_ylabel('Average Rating')\n",
    "axes[1,1].set_title('ğŸ“Š Average Rating by Month', fontweight='bold')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].set_ylim(3.0, 4.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print insights\n",
    "print(f\"\\nğŸ” Temporal Insights:\")\n",
    "print(f\"   ğŸ“… Most active day: {weekday_names[weekday_ratings.idxmax()]} ({weekday_ratings.max():,} ratings)\")\n",
    "print(f\"   ğŸ• Peak rating hour: {hourly_ratings.idxmax()}:00 ({hourly_ratings.max():,} ratings)\")\n",
    "print(f\"   ğŸ“† Most active month: {month_names[monthly_patterns.idxmax()-1]} ({monthly_patterns.max():,} ratings)\")\n",
    "print(f\"   â­ Highest rated month: {month_names[monthly_avg_rating.idxmax()-1]} (avg: {monthly_avg_rating.max():.3f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## ğŸ” Data Quality Assessment\n",
    "\n",
    "Before building our recommendation system, let's assess the quality of our data and identify any potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "source": [
    "# Data quality assessment\n",
    "print(\"ğŸ” Data Quality Assessment:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Movies dataset quality\n",
    "print(\"ğŸ¬ Movies Dataset:\")\n",
    "print(f\"   ğŸ“Š Total records: {len(movies_df):,}\")\n",
    "print(f\"   ğŸ“Š Duplicate titles: {movies_df['title'].duplicated().sum()}\")\n",
    "print(f\"   ğŸ“Š Missing titles: {movies_df['title'].isna().sum()}\")\n",
    "print(f\"   ğŸ“Š Missing genres: {movies_df['genres'].isna().sum()}\")\n",
    "print(f\"   ğŸ“Š Movies with '(no genres listed)': {(movies_df['genres'] == '(no genres listed)').sum()}\")\n",
    "print(f\"   ğŸ“Š Movies with extractable year: {movies_df['year'].notna().sum()} ({movies_df['year'].notna().mean()*100:.1f}%)\")\n",
    "\n",
    "# Ratings dataset quality\n",
    "print(f\"\\nâ­ Ratings Dataset:\")\n",
    "print(f\"   ğŸ“Š Total records: {len(ratings_df):,}\")\n",
    "print(f\"   ğŸ“Š Duplicate ratings: {ratings_df[['userId', 'movieId']].duplicated().sum()}\")\n",
    "print(f\"   ğŸ“Š Missing values: {ratings_df.isna().sum().sum()}\")\n",
    "print(f\"   ğŸ“Š Invalid ratings (outside 0.5-5.0): {((ratings_df['rating'] < 0.5) | (ratings_df['rating'] > 5.0)).sum()}\")\n",
    "print(f\"   ğŸ“Š Unique users: {ratings_df['userId'].nunique():,}\")\n",
    "print(f\"   ğŸ“Š Unique movies rated: {ratings_df['movieId'].nunique():,}\")\n",
    "\n",
    "# Data consistency checks\n",
    "print(f\"\\nğŸ”— Data Consistency:\")\n",
    "movies_in_ratings = set(ratings_df['movieId'].unique())\n",
    "movies_in_catalog = set(movies_df['movieId'].unique())\n",
    "\n",
    "movies_rated_not_in_catalog = movies_in_ratings - movies_in_catalog\n",
    "movies_in_catalog_not_rated = movies_in_catalog - movies_in_ratings\n",
    "\n",
    "print(f\"   ğŸ“Š Movies rated but not in catalog: {len(movies_rated_not_in_catalog)}\")\n",
    "print(f\"   ğŸ“Š Movies in catalog but never rated: {len(movies_in_catalog_not_rated)} ({len(movies_in_catalog_not_rated)/len(movies_df)*100:.1f}%)\")\n",
    "\n",
    "# Sparsity analysis\n",
    "total_possible_ratings = ratings_df['userId'].nunique() * ratings_df['movieId'].nunique()\n",
    "actual_ratings = len(ratings_df)\n",
    "sparsity = (1 - actual_ratings / total_possible_ratings) * 100\n",
    "\n",
    "print(f\"\\nğŸ“Š Data Sparsity Analysis:\")\n",
    "print(f\"   ğŸ“Š Total possible user-movie combinations: {total_possible_ratings:,}\")\n",
    "print(f\"   ğŸ“Š Actual ratings: {actual_ratings:,}\")\n",
    "print(f\"   ğŸ“Š Data sparsity: {sparsity:.2f}%\")\n",
    "print(f\"   ğŸ“Š Data density: {100-sparsity:.2f}%\")\n",
    "\n",
    "if sparsity > 99:\n",
    "    print(f\"   âš ï¸ High sparsity detected! This will challenge our recommendation algorithms.\")\n",
    "elif sparsity > 95:\n",
    "    print(f\"   âœ… Moderate sparsity - typical for recommendation systems.\")\n",
    "else:\n",
    "    print(f\"   âœ… Low sparsity - excellent for recommendation algorithms!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Key Findings & Recommendations\n",
    "\n",
    "Based on my exploration, here are the key insights that will guide our recommendation system design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "source": [
    "# Generate key findings summary\n",
    "print(\"ğŸ’¡ KEY FINDINGS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ¬ MOVIE INSIGHTS:\")\n",
    "print(f\"   â€¢ Drama ({genre_counts['Drama']:,} movies) and Comedy are most popular genres\")\n",
    "print(f\"   â€¢ Peak movie production was in the {peak_year:.0f}s\")\n",
    "print(f\"   â€¢ {len(movies_in_catalog_not_rated)} movies ({len(movies_in_catalog_not_rated)/len(movies_df)*100:.1f}%) have never been rated (cold start problem)\")\n",
    "\n",
    "print(\"\\nğŸ‘¥ USER BEHAVIOR:\")\n",
    "print(f\"   â€¢ Average user rates {user_stats['num_ratings'].mean():.1f} movies\")\n",
    "print(f\"   â€¢ Users tend to be generous: average rating is {ratings_df['rating'].mean():.2f}/5.0\")\n",
    "print(f\"   â€¢ Rating distribution is skewed toward higher ratings\")\n",
    "print(f\"   â€¢ {user_category_counts['Heavy User (100+ ratings)']} users ({user_category_counts['Heavy User (100+ ratings)']/len(user_stats)*100:.1f}%) are super active\")\n",
    "\n",
    "print(\"\\nâ­ RATING PATTERNS:\")\n",
    "print(f\"   â€¢ {ratings_df['rating'].mode().iloc[0]}â­ is the most common rating ({rating_dist[ratings_df['rating'].mode().iloc[0]]:,} times)\")\n",
    "print(f\"   â€¢ Peak rating activity: {weekday_names[weekday_ratings.idxmax()]} at {hourly_ratings.idxmax()}:00\")\n",
    "print(f\"   â€¢ Most active month: {month_names[monthly_patterns.idxmax()-1]}\")\n",
    "\n",
    "print(\"\\nğŸ¯ RECOMMENDATION SYSTEM IMPLICATIONS:\")\n",
    "print(f\"   âœ… Collaborative Filtering: Feasible with {ratings_df['userId'].nunique():,} users and {len(ratings_df):,} ratings\")\n",
    "print(f\"   âš ï¸ Cold Start: Need content-based approach for {len(movies_in_catalog_not_rated)} unrated movies\")\n",
    "print(f\"   ğŸ“Š Data Sparsity: {sparsity:.2f}% sparsity requires robust algorithms\")\n",
    "print(f\"   ğŸ­ Content-Based: Genre information available for content-based filtering\")\n",
    "print(f\"   ğŸ• Temporal: Consider time-based recommendations (seasonal preferences)\")\n",
    "\n",
    "print(\"\\nğŸš€ RECOMMENDED APPROACH:\")\n",
    "print(\"   1. ğŸ¤ User-Based Collaborative Filtering for personalization\")\n",
    "print(\"   2. ğŸ¬ Item-Based Collaborative Filtering for stability\")\n",
    "print(\"   3. ğŸ­ Content-Based Filtering for cold start movies\")\n",
    "print(\"   4. ğŸ”„ Hybrid approach combining all methods\")\n",
    "print(\"   5. â­ Focus on movies with sufficient ratings (>10) for reliable recommendations\")\n",
    "\n",
    "print(f\"\\nğŸ“Š DATASET SUMMARY:\")\n",
    "print(f\"   ğŸ“ˆ Dataset Quality: HIGH - clean, consistent, well-structured\")\n",
    "print(f\"   ğŸ“Š Size: MEDIUM - perfect for learning and prototyping\")\n",
    "print(f\"   ğŸ¯ Suitability: EXCELLENT for recommendation system development\")\n",
    "print(f\"   âš¡ Processing Speed: FAST - can iterate quickly on algorithms\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ Data exploration complete! Ready to build recommendation algorithms.\")\n",
    "print(f\"ğŸ“… Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
